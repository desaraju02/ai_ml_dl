{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrTZNfh2zi2tg2eVLUvbXd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/desaraju02/ai_ml_dl/blob/main/01_nn_regression_with_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "m7bAEpcBYUza"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzaD5GLsY9YG",
        "outputId": "651144cd-33cf-487c-ba1e-387e3b8427f8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([-7.0,-4.0,-1.0,2.0,5.0,8.0,11.0,14.0])\n",
        "y = np.array([1,2,3,4,5,6,7,8])"
      ],
      "metadata": {
        "id": "ctI7AZIMZbJw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "wqUYK-WoZzL8",
        "outputId": "09ab908a-f473-4429-f27d-0342a636e753"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7db96d7bff90>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Demo tensor for house price prediction\n"
      ],
      "metadata": {
        "id": "Rcx7FOzsbthg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "house_info = tf.constant([\"bedroom\",\"bath\",\"garage\"])\n",
        "house_price = tf.constant([940000])"
      ],
      "metadata": {
        "id": "4Tx3nksXbxdG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Turn our numpy arrays to tensors\n",
        "\n",
        "X = tf.constant(X, dtype=tf.float32)\n",
        "y = tf.constant(y, dtype=tf.float32)\n"
      ],
      "metadata": {
        "id": "K3nuAI3ZlLs8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X,y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cy7ze1T_lUUr",
        "outputId": "ff221f25-024a-46c4-f976-1fc66152b8bd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([1., 2., 3., 4., 5., 6., 7., 8.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "input_shape, output_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Q8A3Lk-lYg-",
        "outputId": "6dfb7415-5007-423d-c20f-27ee7d53b413"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([]), TensorShape([]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Steps in modelling with TensorFlow\n",
        "\n",
        "\n",
        "*   **Creating a model** - Input and output layers as well as hidden layers\n",
        "*   **Compiling model** - define the loss function (a function which tells our model how wrong it is) and the optimizer (tells our model how to improve the patterns its learning) and evaluation metrics (what we can use to interpret the performance of our model)\n",
        "*  **Fitting a model** - leeting the model try to find patterns between X & y (features and labels)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9XIR9PfLlvUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.seed(42)"
      ],
      "metadata": {
        "id": "LQG88axtlyMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 1. Create a model using the sequential api\n",
        "model = tf.keras.Sequential()\n",
        "# model.add(tf.keras.layers.Dense(1, input_shape=[1]))\n",
        "model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "\n",
        "### 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae, optimizer=tf.keras.optimizers.SGD(), metrics=[\"mae\"])\n",
        "\n",
        "### 3. Fit the model\n",
        "model.fit(tf.expand_dims(X,axis=-1),y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbExLAjhnWc6",
        "outputId": "ea252711-f390-4b49-809f-ca4c8fd2614c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - loss: 2.7287 - mae: 2.7287\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.6506 - mae: 2.6506\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 2.5724 - mae: 2.5724\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 2.4943 - mae: 2.4943\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 2.4850 - mae: 2.4850\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 2.4794 - mae: 2.4794\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 2.4737 - mae: 2.4737\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 2.4681 - mae: 2.4681\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 2.4625 - mae: 2.4625\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 2.4569 - mae: 2.4569\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 2.4512 - mae: 2.4512\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 2.4456 - mae: 2.4456\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 2.4400 - mae: 2.4400\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.4344 - mae: 2.4344\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.4288 - mae: 2.4288\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.4231 - mae: 2.4231\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 2.4175 - mae: 2.4175\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.4119 - mae: 2.4119\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 2.4062 - mae: 2.4062\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 2.4006 - mae: 2.4006\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 2.3950 - mae: 2.3950\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 2.3894 - mae: 2.3894\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 2.3837 - mae: 2.3837\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 2.3781 - mae: 2.3781\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 2.3725 - mae: 2.3725\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 2.3669 - mae: 2.3669\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 2.3612 - mae: 2.3612\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 2.3556 - mae: 2.3556\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 2.3500 - mae: 2.3500\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 2.3444 - mae: 2.3444\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 2.3387 - mae: 2.3387\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 2.3331 - mae: 2.3331\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 2.3275 - mae: 2.3275\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 2.3219 - mae: 2.3219\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 2.3162 - mae: 2.3162\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 2.3106 - mae: 2.3106\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 2.3050 - mae: 2.3050\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 2.2994 - mae: 2.2994\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 2.2938 - mae: 2.2938\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 2.2881 - mae: 2.2881\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 2.2825 - mae: 2.2825\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 2.2774 - mae: 2.2774\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 2.2731 - mae: 2.2731\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.2675 - mae: 2.2675\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.2619 - mae: 2.2619\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 2.2563 - mae: 2.2563\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 2.2506 - mae: 2.2506\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 2.2450 - mae: 2.2450\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 2.2394 - mae: 2.2394\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 2.2337 - mae: 2.2337\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 2.2281 - mae: 2.2281\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 2.2225 - mae: 2.2225\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 2.2169 - mae: 2.2169\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.2113 - mae: 2.2113\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.2056 - mae: 2.2056\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.2000 - mae: 2.2000\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 2.1944 - mae: 2.1944\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 2.1888 - mae: 2.1888\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 2.1831 - mae: 2.1831\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 2.1775 - mae: 2.1775\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 2.1719 - mae: 2.1719\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 2.1663 - mae: 2.1663\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 2.1606 - mae: 2.1606\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 2.1550 - mae: 2.1550\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 2.1494 - mae: 2.1494\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 2.1438 - mae: 2.1438\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 2.1381 - mae: 2.1381\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 2.1325 - mae: 2.1325\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 2.1269 - mae: 2.1269\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 2.1213 - mae: 2.1213\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 2.1156 - mae: 2.1156\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 2.1100 - mae: 2.1100\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 2.1044 - mae: 2.1044\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 2.0988 - mae: 2.0988\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 2.0931 - mae: 2.0931\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 2.0875 - mae: 2.0875\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 2.0819 - mae: 2.0819\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.0763 - mae: 2.0763\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.0706 - mae: 2.0706\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 2.0650 - mae: 2.0650\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 2.0594 - mae: 2.0594\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 2.0538 - mae: 2.0538\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 2.0493 - mae: 2.0493\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 2.0444 - mae: 2.0444\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.0388 - mae: 2.0388\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.0331 - mae: 2.0331\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 2.0275 - mae: 2.0275\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 2.0219 - mae: 2.0219\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 2.0163 - mae: 2.0163\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 2.0106 - mae: 2.0106\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 2.0050 - mae: 2.0050\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.9994 - mae: 1.9994\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 1.9938 - mae: 1.9938\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1.9881 - mae: 1.9881\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 1.9825 - mae: 1.9825\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.9769 - mae: 1.9769\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.9713 - mae: 1.9713\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.9656 - mae: 1.9656\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 1.9600 - mae: 1.9600\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 1.9544 - mae: 1.9544\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7db956092510>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgoMJ_EbqpkO",
        "outputId": "dfcb5cb7-05bb-4c39-c34a-af65ed0f34b0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X1 = np.array([17.0])\n",
        "X1 = tf.constant(X1, dtype=tf.float32)\n"
      ],
      "metadata": {
        "id": "YbwVX5DeqziD"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(X1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DTP29gTq79b",
        "outputId": "e6645ec4-e421-4206-8566-6cef5fe7f76d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7db95623ac00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[10.161821]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    }
  ]
}